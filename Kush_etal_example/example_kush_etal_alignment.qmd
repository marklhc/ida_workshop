---
title: "Alignment Optimization"
format:
  gfm:
    toc: true
  pdf:
    toc: true
---

## Load Packages

```{r}
library(mirt)       # for IRT analyses
# install.packages("remotes")
# remotes::install_github("marklhc/pinsearch")
library(pinsearch)  # for noninvariance effect size
library(ggplot2)    # for plotting
library(umx)        # for analyzing harmonized scores
```

## Import Data

Data can be downloaded from <https://github.com/jmk7cj/SEM-mnlfa>.

```{r}
data <- read.csv(here::here("Kush_etal_example/SEM-mnlfa", "data.csv"))
# Define grouping variable
data$group <- data$study_id
# Sort data by group
data <- data[order(data$group), ]
head(data)
# Sample sizes
# Study 1 = FAST; Study 2 = LIFT; Study 3 = PIRC1;
# Study 4 = PIRC2; Study 5 = SAFE
table(data$study_id)
item_names <- names(data)[5:13]  # save item names
```

## Configural Model

Run separate mirts (2PL)

```{r}
groups <- unique(data$group)
# Initialize output
# a. number of observations per group and item
item_n <- matrix(NA,
    nrow = length(groups),
    ncol = length(item_names),
    dimnames = list(groups, item_names))
# b. Matrix of loadings and intercepts
lambda <- nu <- item_n
# c. Loop over groups, fitting a 2PL model to each
for (g in seq_along(groups)) {
    datg <- data[data$group == groups[g], item_names]
    # Drop completely missing items
    item_n[g, ] <- colSums(!is.na(datg))
    itemsg <- which(colSums(!is.na(datg)) > 0)
    fitg <- mirt(datg[names(itemsg)], model = 1,
                 itemtype = "2PL")
    coefg <- coef(fitg, simplify = TRUE)
    lambda[g, names(itemsg)] <- coefg$items[, "a1"]
    nu[g, names(itemsg)] <- coefg$items[, "d"]
}
```

### Configural Parameters

```{r}
#| label: tbl-lambda
#| tbl-cap: Configural Loadings
knitr::kable(t(lambda), digits = 2)
```

```{r}
#| label: tbl-nu
#| tbl-cap: Configural Intercepts
knitr::kable(t(nu), digits = 2)
```

## Alignment Optimization

```{r}
aligned <- sirt::invariance.alignment(
    lambda = lambda,
    nu = nu,
    wgt = sqrt(item_n),
    optimizer = "nlminb",
    eps = .0001,
    control = list(maxit = 10000)
)
```

```{r}
#| label: tbl-alambda
#| tbl-cap: Aligned Loadings
knitr::kable(t(aligned$lambda.aligned), digits = 2)
```

```{r}
#| label: tbl-anu
#| tbl-cap: Aligned Intercepts
knitr::kable(t(aligned$nu.aligned), digits = 2)
```

```{r}
#| label: tbl-apars
#| tbl-cap: Aligned Latent means and variances
knitr::kable(t(aligned$pars), digits = 2)
```

### Quality: Effect size of noninvariance

```{r}
# Note: we need to do this twice as `pinsearch::fmacs()`
# does not handle NAs in the input, so we need to
# treat item 2 (not in Study 1) separately
# pooled SD
vars <- apply(data[item_names],
    MARGIN = 2,
    FUN = \(x) tapply(x,
        INDEX = data$study_id,
        FUN = var, na.rm = TRUE
    )
)
item_n2 <- ifelse(item_n > 0, item_n, NA)
pooled_sd <- sqrt(
    colSums(vars * (item_n2 - 1), na.rm = TRUE) /
        colSums(item_n2 - 1, na.rm = TRUE)
)

# a. Items 1, 3-9
thres1 <- aligned$nu.aligned[, c(1, 3:9)]
colnames(thres1) <- seq_len(ncol(thres1))
# Noninvariance effect size for items 1, 3-9
f1 <- pinsearch::fmacs_ordered(
    thresholds = thres1,
    loadings = aligned$lambda.aligned[, c(1, 3:9)],
    link = "logit",
    pooled_item_sd = pooled_sd[c(1, 3:9)]
)
# b. Item 2
thres2 <- aligned$nu.aligned[-1, 2, drop = FALSE]
colnames(thres2) <- 1
f2 <- pinsearch::fmacs_ordered(
    thresholds = thres2,
    loadings = aligned$lambda.aligned[-1, 2, drop = FALSE],
    link = "logit",
    pooled_item_sd = pooled_sd[2]
)
# Combine to form one effect size vector
f_effsize <- cbind(f1[1, 1, drop = FALSE], f2, f1[1, -1, drop = FALSE])
knitr::kable(t(f_effsize), digits = 2)
```

The magnitude of noninvariance effect size is not trivial (with fmacs > .1) for most items.

## Compute Harmonized Factor Scores

```{r}
# Refit the configural model, with latent means and variances
# from the aligned parameters
aligned_pars <- aligned$pars
# Define a syntax template to allow latent means and
# variances to be substituted by the aligned values
mod <- "
  f = 1-[I]
  START = (GROUP, MEAN_1, [mu]), (GROUP, COV_11, [sigma2])
"
# Substitute into the aligned means and variances
fsg <- NULL  # place holder for factor scores
for (g in seq_along(groups)) {
    datg <- data[data$group == groups[g], item_names]
    # Drop completely missing items
    itemsg <- which(item_n[g, ] > 0)
    modg <- gsub("\\[I\\]", replacement = length(itemsg), mod)
    modg <- gsub("\\[mu\\]", replacement = aligned_pars[g, 1], modg)
    # Note: aligned psi is latent SD, but `mirt`
    # needs latent variance (i.e., SD^2)
    modg <- gsub("\\[sigma2\\]", replacement = aligned_pars[g, 2]^2, modg)
    fitg <- mirt(datg[names(itemsg)], model = modg,
                 itemtype = "2PL")
    fsg <- rbind(
        fsg,
        data.frame(
            fscores(fitg,
                method = "EAP", full.scores.SE = TRUE
            ),
            group = groups[g],
            mean_eta = aligned_pars[g, 1],
            sd_eta = aligned_pars[g, 2]
        )
    )
}
```

```{r}
# Save factor scores
saveRDS(fsg, file = here::here("Kush_etal_example", "fsg.RDS"))
```

### Reliability

```{r}
# Average reliability
rel_avg <- var(fsg[, 1], na.rm = TRUE) /
    (var(fsg[, 1], na.rm = TRUE) + mean(fsg[, 2]^2, na.rm = TRUE))
rel_avg
# Group-specific reliability
relg <- tapply(fsg, INDEX = fsg$group,
    FUN = \(x) var(x[, 1], na.rm = TRUE) /
        (var(x[, 1], na.rm = TRUE) + mean(x[, 2]^2, na.rm = TRUE)))
relg
```

## Analyses of Harmonized Scores

### Descriptives

```{r}
ggplot(fsg, aes(x = f)) +
    geom_histogram() +
    facet_wrap(~ group) +
    labs(x = "EAP score")
```

### Factor score regression (no reliability adjustment)

Using EAP scores to predict high school completion with probit regression

```{r}
# Merged with other variables
# Warning: the code requires data to be sorted by study_id before analyses
data <- cbind(data, fsg)
# GLM (probit regression); interaction not significant
m_int <- glm(hs ~ f * study_id, data = data, family = binomial("probit"))
anova(m_int)
m_main <- glm(hs ~ f + study_id, data = data, family = binomial("probit"))
anova(m_main)
summary(m_main)
```

Using `umx` (without unreliability adjustment)

```{r}
#| results: asis
# Recode discrete variable to be used with OpenMx
data$hs2 <- mxFactor(data$hs, levels = c(0, 1))
# Create dummy variables for Study ID
data <- cbind(data, model.matrix(~ study_id, data = data)[, -1])
# Pooled analysis without adjusting for unreliability
# TOCA-R -> high school completion
probitreg_umx <- umxRAM("
  hs2 ~ f + study_idLIFT + study_idPIRC1 + study_idPIRC2 + study_idSAFE
  hs2 ~ 0 * 1
  hs2 ~~ 1 * hs2
",
    data = data,
    tryHard = "ordinal"  # try hard for convergence
)
# plot(probitreg_umx)  # path diagram
```

### Two-Stage Path Analysis

Adjusting for measurement error

```{r}
#| results: asis
# Define loading and error variances
# Loading = 1 - SE^2 / latent variance
data$rel_f <- 1 - data$SE_f^2 / data$sd_eta^2
# Error variance = SE^2 * reliability
data$ev_f <- data$SE_f^2 * data$rel_f
# Drop rows with missing rel_f
data2 <- data[!is.na(data$rel_f), ]
# Incorporate measurement model for factor scores
probitreg_2spa <- umxRAM(
    "2spa",
    # Main effects of EAP scores and study indicators
    umxPath(c("eta", "study_idLIFT", "study_idPIRC1",
              "study_idPIRC2", "study_idSAFE"),
            to = "hs2"),
    # Loading = reliability (as definition variable)
    umxPath("eta", to = "f", labels = "data.rel_f", free = FALSE),
    # Error variance (as definition variable)
    umxPath(var = "f", labels = "data.ev_f", free = FALSE),
    # Covariances of predictors
    umxPath(unique.pairs = c("eta", "study_idLIFT", "study_idPIRC1",
                             "study_idPIRC2", "study_idSAFE")),
    # Means of predictors
    umxPath(means = c("eta", "study_idLIFT", "study_idPIRC1",
                      "study_idPIRC2", "study_idSAFE")),
    # For model identification: Fix latent variate
    # to be standard normal
    umxPath(v1m0 = "hs2"),
    data = data2,
    tryHard = "ordinal"
)
```

## Sensitivity Analysis

Using sum/mean scores

```{r}
data$toca_mean <- rowMeans(data[item_names], na.rm = TRUE)
# Scatterplot
plot(x = data$toca_mean, y = fsg[, 1], xlab = "Mean scores", ylab = "EAP scores")
cor(data$toca_mean, fsg[, 1], use = "complete")
```

Probit regression with mean scores; note that the scale of the predictors are different, so the coefficients are not comparable.

```{r}
# GLM (probit regression); interaction not significant
m_int_meanscore <- glm(hs ~ toca_mean * study_id, data = data, family = binomial("probit"))
anova(m_int_meanscore)
m_main_meanscore <- glm(hs ~ toca_mean + study_id, data = data, family = binomial("probit"))
anova(m_main_meanscore)
summary(m_main_meanscore)
```
